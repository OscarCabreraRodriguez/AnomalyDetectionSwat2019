{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mek8t7e6Dzri"
   },
   "source": [
    "# Util-kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSIef1YZdxBM",
    "outputId": "4258ef1a-887b-4c22-e200-884c31f36b9c"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt     \n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UuZYla8vA88K"
   },
   "outputs": [],
   "source": [
    "attacks = [\n",
    "    {\"start\":\"2019-07-20 15:08:46.004013+08:00\", \"end\":\"2019-07-20 15:10:31.004013+08:00\", \"cols\": [\"FIT 401\", \"UV401\"]},\n",
    "    {\"start\":\"2019-07-20 15:15:00.004013+08:00\", \"end\":\"2019-07-20 15:19:32.004013+08:00\", \"cols\": [\"LIT 301\"]},\n",
    "    {\"start\":\"2019-07-20 15:26:57.004013+08:00\", \"end\":\"2019-07-20 15:30:48.004013+08:00\", \"cols\": [\"P601 Status\"]},\n",
    "    {\"start\":\"2019-07-20 15:38:50.004013+08:00\", \"end\":\"2019-07-20 15:46:20.004013+08:00\", \"cols\": [\"MV201\", \"P101 Status\"]},\n",
    "    {\"start\":\"2019-07-20 15:54:00.004013+08:00\", \"end\":\"2019-07-20 15:56:00.004013+08:00\", \"cols\": [\"MV 501\"]},\n",
    "    {\"start\":\"2019-07-20 16:02:56.004013+08:00\", \"end\":\"2019-07-20 16:16:18.004013+08:00\", \"cols\": [\"P301 Status\"]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gNEcoZYM-sHC"
   },
   "outputs": [],
   "source": [
    "global raw_df\n",
    "raw_df = None\n",
    "def read_data():\n",
    "    global raw_df\n",
    "    if raw_df is None:\n",
    "      raw_df = pd.read_excel('SWaT_dataset_Jul 19 v2.xlsx', parse_dates = ['GMT +0'], index_col = 'GMT +0')\n",
    "      raw_df = raw_df.rename(columns=lambda x: x.strip())\n",
    "      raw_df.index = raw_df.index.tz_convert('Asia/Singapore') + pd.Timedelta(minutes=2)\n",
    "    return raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nGo-8JoKJafF"
   },
   "outputs": [],
   "source": [
    "def keep_columns(all, to_keep=[\"FIT 401\", \"LIT 301\"]):\n",
    "    if len(to_keep):\n",
    "      return list(set(all).intersection(set(to_keep)))\n",
    "    return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tXqkrrmXh7D9"
   },
   "outputs": [],
   "source": [
    "def split_feature(df):\n",
    "    cat_features = []\n",
    "    numeric_features = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) < 4:\n",
    "          cat_features.append(col)\n",
    "        else: numeric_features.append(col)\n",
    "    return cat_features, numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rDCFIq3wICzk"
   },
   "outputs": [],
   "source": [
    "def preprocess_cat(df): \n",
    "    df = df.copy() \n",
    "    df['LS 201'] = np.where(df['LS 201'] == 'Active', 1, 0)\n",
    "    df['LS 202'] = np.where(df['LS 202'] == 'Active', 1, 0)\n",
    "    df['LSL 203'] = np.where(df['LSL 203'] == 'Inactive', 0, 1)\n",
    "    df['LSLL 203'] = np.where(df['LSLL 203'] == 'Active', 1, 0)\n",
    "    df['LS 401'] = np.where(df['LS 401'] == 'Active', 1, 0)\n",
    "    df['LSH 601'] = np.where(df['LSH 601'] == 'Active', 1, 0)\n",
    "    df['LSH 602'] = np.where(df['LSH 602'] == 'Active', 1, 0)\n",
    "    df['LSH 603'] = np.where(df['LSH 603'] == 'Active', 1, 0)\n",
    "    df['LSL 601'] = np.where(df['LSL 601'] == 'Active', 1, 0)\n",
    "    df['LSL 602'] = np.where(df['LSL 602'] == 'Active', 1, 0)\n",
    "    df['LSL 603'] = np.where(df['LSL 603'] == 'Active', 1, 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0g9HKPlE_5N4"
   },
   "outputs": [],
   "source": [
    "def preprocess(df, cols, to_plot=False):\n",
    "    \n",
    "    enc_df = None\n",
    "    minmax_scale = None\n",
    "    cat_features, numeric_features = split_feature(df)\n",
    "    cat_features = keep_columns(cat_features, cols)\n",
    "    numeric_features = keep_columns(numeric_features, cols)\n",
    "    cols = numeric_features + cat_features\n",
    "\n",
    "    df = df.copy()\n",
    "    df = df[cols]\n",
    "    #OneHotEncode categorical data\n",
    "    if len(cat_features) > 0:\n",
    "      encoder = OneHotEncoder(sparse = False)\n",
    "      enc_df = pd.DataFrame(encoder.fit_transform(df[cat_features]))\n",
    "      enc_df.index = df.index\n",
    "    \n",
    "    if len(numeric_features) > 0:\n",
    "        # Normalize numerical data\n",
    "        minmax_scale = pd.DataFrame(MinMaxScaler().fit_transform(df[numeric_features]))\n",
    "        minmax_scale.index = df.index \n",
    "    \n",
    "    if isinstance(enc_df, pd.DataFrame) and  isinstance(minmax_scale, pd.DataFrame):\n",
    "        set_val = pd.concat([enc_df, minmax_scale], axis=1, ignore_index=True) \n",
    "        set_val = set_val.reindex(df.index)\n",
    "    elif isinstance(enc_df, pd.DataFrame):\n",
    "         set_val = enc_df\n",
    "    elif isinstance(minmax_scale, pd.DataFrame):\n",
    "         set_val = minmax_scale\n",
    "    else:\n",
    "         set_val = -1\n",
    "\n",
    "    return set_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3yVdPFQk_V1g"
   },
   "outputs": [],
   "source": [
    "def get_clean_df(cols=[], to_plot=False):\n",
    "    df = read_data()\n",
    "    df = preprocess_cat(df)\n",
    "    sel = VarianceThreshold(threshold=0)\n",
    "    sel.fit(df)  # fit finds the features with zero variance\n",
    "    df = df[df.columns[sel.get_support()]]\n",
    "    # print(\"Number of columns \" + df.columns)\n",
    "    df = preprocess(df, cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9gt3_bJdc5bi"
   },
   "outputs": [],
   "source": [
    "def list_to_str(cols):\n",
    "    return \"_\".join(cols).replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ykzGdksCozuG"
   },
   "outputs": [],
   "source": [
    "def evaluate(df, start, end, ev_col):\n",
    "    x = df[((df.index<=start)&(df.index<=end))]\n",
    "    return len(x[x[ev_col]==-1])/len(x), len(df[df[ev_col]==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ZrK-wQzMvXWJ"
   },
   "outputs": [],
   "source": [
    "def evaluate_all_features(df, attacks, ev_col):\n",
    "    result = []\n",
    "    ratio = 0\n",
    "    for attack in attacks:\n",
    "      x = df[((df.index<=attack[\"start\"])&(df.index<=attack[\"end\"]))]\n",
    "      ratio += len(x[x[ev_col]==-1])/len(x)\n",
    "    return ratio/len(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "QdSRG1vFrEsh"
   },
   "outputs": [],
   "source": [
    "def plot_ts(x, y, colors, title):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(25)\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.set_title(title)\n",
    "    sc = ax1.scatter(x,y, s=10,c=colors)\n",
    "    plt.colorbar(sc)\n",
    "    for attack in attacks:\n",
    "      ax1.fill_between(x, 0, 1,where=(x >= attack[\"start\"] )& (x<=attack[\"end\"]),\n",
    "                     color='red', alpha=0.5, transform=ax1.get_xaxis_transform())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "upKjupizFcm_"
   },
   "outputs": [],
   "source": [
    "def unsupervised_iso_grid_search(df, max_samples, contaminations, n_estimators, max_features, attack):\n",
    "    hypyer_parameters = [max_samples, contaminations, n_estimators, max_features]\n",
    "    modified_df = df.copy()\n",
    "    df_orginal = df.copy()\n",
    "    best_model = {\"model_name\": None, \"anomaly_percentage\":0, \"anomlaies_num\":0}\n",
    "    for a, b, c, d in itertools.product(*hypyer_parameters):\n",
    "        model_name = f\"iso_{a}_{b}_{c}_{d}\"\n",
    "        model = IsolationForest(max_samples=a, contamination=b, n_estimators=c, max_features=d)\n",
    "        model.fit(df_orginal)\n",
    "        modified_df[model_name] = model.predict(df_orginal)\n",
    "        anomaly_percentage, anomlaies_num = evaluate(modified_df, attack[\"start\"], attack[\"end\"], model_name)\n",
    "        if best_model[\"anomaly_percentage\"] <  anomaly_percentage:\n",
    "           best_model[\"anomaly_percentage\"] = anomaly_percentage\n",
    "           best_model[\"model_name\"] = model_name\n",
    "           best_model[\"anomlaies_num\"] = anomlaies_num\n",
    "        # print(f\"{model_name}: {anomaly_percentage} - {best_model['anomlaies_num']}\")  \n",
    "    return best_model      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Vbfp52_LGzDh"
   },
   "outputs": [],
   "source": [
    "def fit_predict(all_features=False):\n",
    "  if all_features is False:\n",
    "      for x in attacks:\n",
    "          df = get_clean_df(x[\"cols\"])\n",
    "          features = list_to_str(x[\"cols\"])\n",
    "          best_model = unsupervised_iso_grid_search(df, max_samples=[100, 200, 500, 'auto'],\n",
    "                                    n_estimators=[50, 100, 200],\n",
    "                                    contaminations=[0.1, 0.2, 0.3, 0.5,'auto'],\n",
    "                                    max_features=[1],\n",
    "                                    attack=x) # attack info used for evaluation\n",
    "          print(f\"Best model on {features} is {best_model['model_name']} with ratio {best_model['anomaly_percentage']} and {best_model['anomlaies_num']} total anomalies\")\n",
    "  else:\n",
    "      df = get_clean_df(['FIT 401',\n",
    "            'UV401',\n",
    "            'LIT 301',\n",
    "            'P601 Status',\n",
    "            'MV201',\n",
    "            'P101 Status',\n",
    "            'MV 501',\n",
    "            'P301 Status'])\n",
    "      best_model = unsupervised_iso_grid_search_all_features(df, max_samples=['auto'],\n",
    "                                    n_estimators=[50],\n",
    "                                    max_features=[1],\n",
    "                                    contaminations=['auto']) # attack info used for evaluation\n",
    "      print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "O7UAgArvWu7A"
   },
   "outputs": [],
   "source": [
    "def fit_predict_single(df, max_samples=100, contaminations='auto', n_estimators=50, max_features=1, features=[]):\n",
    "    df_orginal = df.copy()\n",
    "    model_name = f\"iso_{max_samples}_{contaminations}_{n_estimators}_{max_features}\"\n",
    "    model = IsolationForest(max_samples=max_samples, contamination=contaminations, n_estimators=n_estimators, max_features=max_features)\n",
    "    model.fit(df_orginal)\n",
    "    df[model_name] = model.predict(df_orginal)\n",
    "    res = evaluate_all_features(df, attacks, model_name)\n",
    "#     plot_df = read_data()\n",
    "#     plot_df = preprocess_cat(plot_df)\n",
    "#     plot_df = plot_df[features]\n",
    "#     plot_df[features] = MinMaxScaler().fit_transform(plot_df[features])\n",
    "#     plot_df.index = df.index\n",
    "\n",
    "#     for feature in features:\n",
    "#       plot_ts(plot_df.index, plot_df[feature], df[model_name], title=feature)\n",
    "    return res, model, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_iso_grid_search_all_features(df, max_samples=[100, 200, 500, 'auto'],\n",
    "                                    n_estimators=[50, 100, 200],\n",
    "                                    contaminations=[0.1, 0.2, 0.3, 0.5,'auto'],\n",
    "                                    max_features=[1],attacks=attacks):\n",
    "    hypyer_parameters = [max_samples, contaminations, n_estimators, max_features]\n",
    "    modified_df = df.copy()\n",
    "    df_orginal = df.copy()\n",
    "    best_model = {\"model\":None, \"name\":None, \"res\":0}\n",
    "    for a, b, c, d in itertools.product(*hypyer_parameters):\n",
    "        print(a,b,c,d)\n",
    "        res, model, model_name = fit_predict_single(df, max_samples=a, contaminations=b, n_estimators=50, max_features=1, features=features)\n",
    "        print(f\"{model_name}: {res}\")\n",
    "        if res > best_model[\"res\"]:\n",
    "            best_model[\"res\"] = res\n",
    "            best_model[\"name\"] = model_name\n",
    "            best_model[\"model\"] = model\n",
    "    print(f\"best model is {best_model['name']}: {best_model['res']}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uZggFO9nwgQw",
    "outputId": "8ab2f9a0-939a-499f-f409-e7a506fa59cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.1 50 1\n",
      "iso_100_0.1_50_1: 0.1071052457245044\n",
      "100 0.1 100 1\n",
      "iso_100_0.1_50_1: 0.10217766722071653\n",
      "100 0.1 200 1\n",
      "iso_100_0.1_50_1: 0.09358758028972881\n",
      "100 0.2 50 1\n",
      "iso_100_0.2_50_1: 0.1510752587926951\n",
      "100 0.2 100 1\n",
      "iso_100_0.2_50_1: 0.15578924345687448\n",
      "100 0.2 200 1\n",
      "iso_100_0.2_50_1: 0.16111234817295625\n",
      "100 0.3 50 1\n",
      "iso_100_0.3_50_1: 0.28781228833985784\n",
      "100 0.3 100 1\n",
      "iso_100_0.3_50_1: 0.21081249317129247\n",
      "100 0.3 200 1\n",
      "iso_100_0.3_50_1: 0.24848429956927073\n",
      "100 0.5 50 1\n",
      "iso_100_0.5_50_1: 0.3732991911159879\n",
      "100 0.5 100 1\n",
      "iso_100_0.5_50_1: 0.39812627008811585\n",
      "100 0.5 200 1\n",
      "iso_100_0.5_50_1: 0.436273923506376\n",
      "100 auto 50 1\n",
      "iso_100_auto_50_1: 0.13901781587643455\n",
      "100 auto 100 1\n",
      "iso_100_auto_50_1: 0.1863534393078794\n",
      "100 auto 200 1\n",
      "iso_100_auto_50_1: 0.20924715648001277\n",
      "200 0.1 50 1\n",
      "iso_200_0.1_50_1: 0.05718786501743631\n",
      "200 0.1 100 1\n",
      "iso_200_0.1_50_1: 0.1051844624872761\n",
      "200 0.1 200 1\n",
      "iso_200_0.1_50_1: 0.0876158037057293\n",
      "200 0.2 50 1\n",
      "iso_200_0.2_50_1: 0.14737472175015823\n",
      "200 0.2 100 1\n",
      "iso_200_0.2_50_1: 0.13680358055885256\n",
      "200 0.2 200 1\n",
      "iso_200_0.2_50_1: 0.14106317779661692\n",
      "200 0.3 50 1\n",
      "iso_200_0.3_50_1: 0.25181317469645587\n",
      "200 0.3 100 1\n",
      "iso_200_0.3_50_1: 0.2159974152969366\n",
      "200 0.3 200 1\n",
      "iso_200_0.3_50_1: 0.2343462701580368\n",
      "200 0.5 50 1\n",
      "iso_200_0.5_50_1: 0.433804000468093\n",
      "200 0.5 100 1\n",
      "iso_200_0.5_50_1: 0.4285308270358448\n",
      "200 0.5 200 1\n",
      "iso_200_0.5_50_1: 0.41201724121241967\n",
      "200 auto 50 1\n",
      "iso_200_auto_50_1: 0.13877880225734346\n",
      "200 auto 100 1\n",
      "iso_200_auto_50_1: 0.18505233072622018\n",
      "200 auto 200 1\n",
      "iso_200_auto_50_1: 0.1067818878261032\n",
      "500 0.1 50 1\n",
      "iso_500_0.1_50_1: 0.08130838085732987\n",
      "500 0.1 100 1\n",
      "iso_500_0.1_50_1: 0.09915182283556122\n",
      "500 0.1 200 1\n",
      "iso_500_0.1_50_1: 0.09214832694161329\n",
      "500 0.2 50 1\n",
      "iso_500_0.2_50_1: 0.17558951193771088\n",
      "500 0.2 100 1\n",
      "iso_500_0.2_50_1: 0.1661827183805173\n",
      "500 0.2 200 1\n",
      "iso_500_0.2_50_1: 0.17967702064501032\n",
      "500 0.3 50 1\n",
      "iso_500_0.3_50_1: 0.26670175640212573\n",
      "500 0.3 100 1\n",
      "iso_500_0.3_50_1: 0.20370351535067777\n",
      "500 0.3 200 1\n",
      "iso_500_0.3_50_1: 0.25434838304989454\n",
      "500 0.5 50 1\n",
      "iso_500_0.5_50_1: 0.4901814362021631\n",
      "500 0.5 100 1\n",
      "iso_500_0.5_50_1: 0.4737569906004353\n",
      "500 0.5 200 1\n",
      "iso_500_0.5_50_1: 0.3669802932287538\n",
      "500 auto 50 1\n",
      "iso_500_auto_50_1: 0.1301311410720122\n",
      "500 auto 100 1\n",
      "iso_500_auto_50_1: 0.13489477155838406\n",
      "500 auto 200 1\n",
      "iso_500_auto_50_1: 0.08438208350095243\n",
      "auto 0.1 50 1\n",
      "iso_auto_0.1_50_1: 0.09412025263312414\n",
      "auto 0.1 100 1\n",
      "iso_auto_0.1_50_1: 0.101494984440258\n",
      "auto 0.1 200 1\n",
      "iso_auto_0.1_50_1: 0.09454692192207009\n",
      "auto 0.2 50 1\n",
      "iso_auto_0.2_50_1: 0.14352666218469481\n",
      "auto 0.2 100 1\n",
      "iso_auto_0.2_50_1: 0.19482959531042013\n",
      "auto 0.2 200 1\n",
      "iso_auto_0.2_50_1: 0.1702107889090214\n",
      "auto 0.3 50 1\n",
      "iso_auto_0.3_50_1: 0.25038199535124955\n",
      "auto 0.3 100 1\n",
      "iso_auto_0.3_50_1: 0.20141587749714\n",
      "auto 0.3 200 1\n",
      "iso_auto_0.3_50_1: 0.2436768005226222\n",
      "auto 0.5 50 1\n",
      "iso_auto_0.5_50_1: 0.40919508069183785\n",
      "auto 0.5 100 1\n",
      "iso_auto_0.5_50_1: 0.40069514674357226\n",
      "auto 0.5 200 1\n",
      "iso_auto_0.5_50_1: 0.3864783061627297\n",
      "auto auto 50 1\n",
      "iso_auto_auto_50_1: 0.10631668895778723\n",
      "auto auto 100 1\n",
      "iso_auto_auto_50_1: 0.18222984237281412\n",
      "auto auto 200 1\n",
      "iso_auto_auto_50_1: 0.0858088675035041\n",
      "best model is iso_500_0.5_50_1: 0.4901814362021631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': IsolationForest(contamination=0.5, max_features=1, max_samples=500,\n",
       "                 n_estimators=50),\n",
       " 'name': 'iso_500_0.5_50_1',\n",
       " 'res': 0.4901814362021631}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['FIT 401',\n",
    "            'UV401',\n",
    "            'LIT 301',\n",
    "            'P601 Status',\n",
    "            'MV201',\n",
    "            'P101 Status',\n",
    "            'MV 501',\n",
    "            'P301 Status']\n",
    "df = get_clean_df([])\n",
    "unsupervised_iso_grid_search_all_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
