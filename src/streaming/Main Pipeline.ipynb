{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4985828a-0ec3-46ea-b45d-7907938f649a",
   "metadata": {},
   "source": [
    "# Main Pipeline\n",
    "Kafka Consumer -> PySpark -> Sketches -> Storing in InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ddb60-079e-40d0-93b7-e4742326fa10",
   "metadata": {},
   "source": [
    "## Kafka Consumer receiving rows and storing them Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57921d12-2198-4ded-a935-0740adee2c3e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/conda/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: mmh3 in /opt/conda/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: pysad in /opt/conda/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from pysad) (1.1.3)\n",
      "Requirement already satisfied: pyod>=0.7.7.1 in /opt/conda/lib/python3.10/site-packages (from pysad) (1.0.6)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from pysad) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from pysad) (1.23.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyod>=0.7.7.1->pysad) (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from pyod>=0.7.7.1->pysad) (3.6.2)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from pyod>=0.7.7.1->pysad) (0.13.5)\n",
      "Requirement already satisfied: numba>=0.51 in /opt/conda/lib/python3.10/site-packages (from pyod>=0.7.7.1->pysad) (0.56.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pyod>=0.7.7.1->pysad) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->pysad) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.51->pyod>=0.7.7.1->pysad) (65.5.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51->pyod>=0.7.7.1->pysad) (0.39.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod>=0.7.7.1->pysad) (9.2.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from statsmodels->pyod>=0.7.7.1->pysad) (1.5.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels->pyod>=0.7.7.1->pysad) (0.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels->pyod>=0.7.7.1->pysad) (2022.6)\n",
      "Requirement already satisfied: combo in /opt/conda/lib/python3.10/site-packages (0.1.3)\n",
      "Requirement already satisfied: numba>=0.35 in /opt/conda/lib/python3.10/site-packages (from combo) (0.56.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from combo) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.10/site-packages (from combo) (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from combo) (3.6.2)\n",
      "Requirement already satisfied: pyod in /opt/conda/lib/python3.10/site-packages (from combo) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.10/site-packages (from combo) (1.23.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from combo) (1.9.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.35->combo) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.35->combo) (65.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20->combo) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->combo) (4.38.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pyod->combo) (1.16.0)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from pyod->combo) (0.13.5)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from statsmodels->pyod->combo) (1.5.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels->pyod->combo) (0.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels->pyod->combo) (2022.6)\n",
      "Requirement already satisfied: influxdb_client in /opt/conda/lib/python3.10/site-packages (1.34.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from influxdb_client) (65.5.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from influxdb_client) (1.26.11)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from influxdb_client) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from influxdb_client) (2.8.2)\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /opt/conda/lib/python3.10/site-packages (from influxdb_client) (4.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from reactivex>=4.0.4->influxdb_client) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python\n",
    "!pip install mmh3\n",
    "!pip install pysad\n",
    "!pip install combo\n",
    "!pip install influxdb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad64e9b-640b-4bc3-9b09-13ee1ca38463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b4d9a2-4a4c-43cd-b3d0-d1a0b9254d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b62be9-033b-4561-a104-f16a61756da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer('swat_elte',bootstrap_servers=['kafka-server:9092'],\n",
    "                         group_id=None,\n",
    "                         # auto_offset_reset='earliest', \n",
    "                         api_version=(0,10,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bedbe2-ca8c-4dda-b623-cbd7936bac1e",
   "metadata": {},
   "source": [
    "### Consumer part\n",
    "You will need to run producer notebook to get the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f1e3a5-6efb-47bb-83af-34ea45e8a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Consumed:  1000\n",
      "Rows Consumed:  2000\n",
      "Rows Consumed:  3000\n",
      "Rows Consumed:  4000\n",
      "Rows Consumed:  5000\n",
      "Rows Consumed:  6000\n",
      "Rows Consumed:  7000\n",
      "Rows Consumed:  8000\n",
      "Rows Consumed:  9000\n",
      "Rows Consumed:  10000\n",
      "Rows Consumed:  11000\n",
      "Rows Consumed:  12000\n",
      "Rows Consumed:  13000\n",
      "Rows Consumed:  14000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "for message in consumer:\n",
    "    message = message.value\n",
    "    if len(message) < 10:\n",
    "        break\n",
    "    try:\n",
    "        df_row = pd.json_normalize(json.loads(message))\n",
    "        df = pd.concat([df, df_row])\n",
    "        if len(df) % 1000 == 0:\n",
    "            i += 1000\n",
    "            print(\"Rows Consumed: \", i)\n",
    "    except NotImplementedError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f3e785-cbd7-438e-946b-3737bd360d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14996, 78)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMT +0</th>\n",
       "      <th>FIT 101</th>\n",
       "      <th>LIT 101</th>\n",
       "      <th>MV 101</th>\n",
       "      <th>P1_STATE</th>\n",
       "      <th>P101 Status</th>\n",
       "      <th>P102 Status</th>\n",
       "      <th>AIT 201</th>\n",
       "      <th>AIT 202</th>\n",
       "      <th>AIT 203</th>\n",
       "      <th>...</th>\n",
       "      <th>LSH 601</th>\n",
       "      <th>LSH 602</th>\n",
       "      <th>LSH 603</th>\n",
       "      <th>LSL 601</th>\n",
       "      <th>LSL 602</th>\n",
       "      <th>LSL 603</th>\n",
       "      <th>P6 STATE</th>\n",
       "      <th>P601 Status</th>\n",
       "      <th>P602 Status</th>\n",
       "      <th>P603 Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-20 08:39:59</td>\n",
       "      <td>4.323736</td>\n",
       "      <td>492.896881</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>131.408615</td>\n",
       "      <td>9.313829</td>\n",
       "      <td>257.933868</td>\n",
       "      <td>...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Active</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-20 08:39:58</td>\n",
       "      <td>4.323736</td>\n",
       "      <td>492.465100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>131.408615</td>\n",
       "      <td>9.316713</td>\n",
       "      <td>257.703156</td>\n",
       "      <td>...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Active</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-20 08:39:57</td>\n",
       "      <td>4.303558</td>\n",
       "      <td>492.308100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>131.408615</td>\n",
       "      <td>9.317354</td>\n",
       "      <td>257.703156</td>\n",
       "      <td>...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Active</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-20 08:39:56</td>\n",
       "      <td>4.253915</td>\n",
       "      <td>491.405273</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>131.408615</td>\n",
       "      <td>9.317354</td>\n",
       "      <td>257.703156</td>\n",
       "      <td>...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Active</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-20 08:39:55</td>\n",
       "      <td>4.200429</td>\n",
       "      <td>491.169769</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>131.408615</td>\n",
       "      <td>9.319918</td>\n",
       "      <td>257.703156</td>\n",
       "      <td>...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Active</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GMT +0   FIT 101     LIT 101  MV 101  P1_STATE  P101 Status  \\\n",
       "0  2019-07-20 08:39:59  4.323736  492.896881       2         2            2   \n",
       "0  2019-07-20 08:39:58  4.323736  492.465100       2         2            2   \n",
       "0  2019-07-20 08:39:57  4.303558  492.308100       2         2            2   \n",
       "0  2019-07-20 08:39:56  4.253915  491.405273       2         2            2   \n",
       "0  2019-07-20 08:39:55  4.200429  491.169769       2         2            2   \n",
       "\n",
       "   P102 Status     AIT 201   AIT 202     AIT 203  ...  LSH 601 LSH 602  \\\n",
       "0            1  131.408615  9.313829  257.933868  ...   Active  Active   \n",
       "0            1  131.408615  9.316713  257.703156  ...   Active  Active   \n",
       "0            1  131.408615  9.317354  257.703156  ...   Active  Active   \n",
       "0            1  131.408615  9.317354  257.703156  ...   Active  Active   \n",
       "0            1  131.408615  9.319918  257.703156  ...   Active  Active   \n",
       "\n",
       "    LSH 603   LSL 601   LSL 602  LSL 603  P6 STATE  P601 Status  P602 Status  \\\n",
       "0  Inactive  Inactive  Inactive   Active         2            1            1   \n",
       "0  Inactive  Inactive  Inactive   Active         2            1            1   \n",
       "0  Inactive  Inactive  Inactive   Active         2            1            1   \n",
       "0  Inactive  Inactive  Inactive   Active         2            1            1   \n",
       "0  Inactive  Inactive  Inactive   Active         2            1            1   \n",
       "\n",
       "   P603 Status  \n",
       "0            1  \n",
       "0            1  \n",
       "0            1  \n",
       "0            1  \n",
       "0            1  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4281b301-35ef-4e7d-9ec4-957bc85504f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+------+--------+-----------+-----------+----------+--------+----------+----------+--------+--------+--------+--------+-----+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------+----------+----------+----------+----------+----------+------+------+------+------+--------+-----------+-----------+-------+----------+-----------+----------+--------+--------+-----------+-----------+-----------+-----------+-----+----------+----------+----------+----------+-----------+-----------+-----------+----------+------+------+------+------+--------+-----------+-----------+----------+----------+----------+----------+-------+-------+--------+--------+--------+-------+--------+-----------+-----------+-----------+\n",
      "|             GMT +0|   FIT 101|   LIT 101|MV 101|P1_STATE|P101 Status|P102 Status|   AIT 201| AIT 202|   AIT 203|   FIT 201|  LS 201|  LS 202| LSL 203|LSLL 203|MV201|P2_STATE|P201 Status|P202 Status|P203 Status|P204 Status|P205 Status|P206 Status|P207 Status|P208 Status| AIT 301|   AIT 302|   AIT 303|  DPIT 301|   FIT 301|   LIT 301|MV 301|MV 302|MV 303|MV 304|P3_STATE|P301 Status|P302 Status|AIT 401|   AIT 402|    FIT 401|   LIT 401|  LS 401|P4_STATE|P401 Status|P402 Status|P403 Status|P404 Status|UV401|   AIT 501|   AIT 502|   AIT 503|   AIT 504|    FIT 501|    FIT 502|    FIT 503|   FIT 504|MV 501|MV 502|MV 503|MV 504|P5_STATE|P501 Status|P502 Status|   PIT 501|   PIT 502|   PIT 503|   FIT 601|LSH 601|LSH 602| LSH 603| LSL 601| LSL 602|LSL 603|P6 STATE|P601 Status|P602 Status|P603 Status|\n",
      "+-------------------+----------+----------+------+--------+-----------+-----------+----------+--------+----------+----------+--------+--------+--------+--------+-----+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------+----------+----------+----------+----------+----------+------+------+------+------+--------+-----------+-----------+-------+----------+-----------+----------+--------+--------+-----------+-----------+-----------+-----------+-----+----------+----------+----------+----------+-----------+-----------+-----------+----------+------+------+------+------+--------+-----------+-----------+----------+----------+----------+----------+-------+-------+--------+--------+--------+-------+--------+-----------+-----------+-----------+\n",
      "|2019-07-20 08:39:59|4.32373571|492.896881|     2|       2|          2|          1|131.408615|9.313829|257.933868|2.31365132|Inactive|Inactive|Inactive|Inactive|    2|       2|          1|          1|          2|          1|          2|          1|          1|          1|8.744734|273.103271|134.227539|12.2222929|1.71937346|   883.908|     1|     2|     1|     1|       7|          2|          1|      0|   3.74263|0.807990253|    962.83|Inactive|       4|          2|          1|          1|          1|    2|7.76582956|63.7528839|1016.21381|24.8397846|0.808126152|0.363007575|  0.6059598|0.20990935|     2|     2|     1|     1|      12|          2|          1|  158.8535|2.49895883|113.784927|3.20379E-4| Active| Active|Inactive|Inactive|Inactive| Active|       2|          1|          1|          1|\n",
      "|2019-07-20 08:39:58|4.32373571|  492.4651|     2|       2|          2|          1|131.408615|9.316713|257.703156|2.31365132|Inactive|Inactive|Inactive|Inactive|    2|       2|          1|          1|          2|          1|          2|          1|          1|          1|8.744734|273.103271|134.227539|12.2222929|1.71937346|   883.908|     1|     2|     1|     1|       7|          2|          1|      0|   3.74263|  0.8086305|962.445557|Inactive|       4|          2|          1|          1|          1|    2|7.76582956|63.7528839|1016.21381|24.8397846| 0.80953604|0.357115418|  0.6059598|0.20990935|     2|     2|     1|     1|      12|          2|          1|  158.8535|2.49895883|113.784927|3.20379E-4| Active| Active|Inactive|Inactive|Inactive| Active|       2|          1|          1|          1|\n",
      "|2019-07-20 08:39:57|4.30355835|  492.3081|     2|       2|          2|          1|131.408615|9.317354|257.703156|2.31365132|Inactive|Inactive|Inactive|Inactive|    2|       2|          1|          1|          2|          1|          2|          1|          1|          1|8.744734|273.103271|134.227539|12.2222929|1.71937346|883.387268|     1|     2|     1|     1|       7|          2|          1|      0|   3.74263| 0.80927074|962.637756|Inactive|       4|          2|          1|          1|          1|    2|7.76582956|63.7528839|1016.21381|24.8397846| 0.80953604|0.369155884|  0.6059598|0.20990935|     2|     2|     1|     1|      12|          2|          1|  158.8535|2.49895883|113.784927|3.20379E-4| Active| Active|Inactive|Inactive|Inactive| Active|       2|          1|          1|          1|\n",
      "|2019-07-20 08:39:56|4.25391531|491.405273|     2|       2|          2|          1|131.408615|9.317354|257.703156|2.31429219|Inactive|Inactive|Inactive|Inactive|    2|       2|          1|          1|          2|          1|          2|          1|          1|          1|8.744734|273.103271|134.227539|12.2222929|1.71937346|883.227051|     1|     2|     1|     1|       7|          2|          1|      0|   3.74263| 0.80927074|962.137939|Inactive|       4|          2|          1|          1|          1|    2|7.76582956|63.7528839|1016.21381|24.8397846| 0.80953604|0.374023318|  0.6059598|0.20990935|     2|     2|     1|     1|      12|          2|          1|158.805435|2.49895883|113.784927|3.20379E-4| Active| Active|Inactive|Inactive|Inactive| Active|       2|          1|          1|          1|\n",
      "|2019-07-20 08:39:55|  4.200429|491.169769|     2|       2|          2|          1|131.408615|9.319918|257.703156|2.31608629|Inactive|Inactive|Inactive|Inactive|    2|       2|          1|          1|          2|          1|          2|          1|          1|          1|8.744734|273.103271|134.227539|12.2222929|1.71847665|883.227051|     1|     2|     1|     1|       7|          2|          1|      0|3.69136119| 0.80927074|  961.8688|Inactive|       4|          2|          1|          1|          1|    2|7.76582956|63.7528839|1016.21381|24.8397846| 0.80953604|0.366594076|0.607752144|0.20990935|     2|     2|     1|     1|      12|          2|          1|158.773392|2.49895883|113.784927|3.20379E-4| Active| Active|Inactive|Inactive|Inactive| Active|       2|          1|          1|          1|\n",
      "+-------------------+----------+----------+------+--------+-----------+-----------+----------+--------+----------+----------+--------+--------+--------+--------+-----+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------+----------+----------+----------+----------+----------+------+------+------+------+--------+-----------+-----------+-------+----------+-----------+----------+--------+--------+-----------+-----------+-----------+-----------+-----+----------+----------+----------+----------+-----------+-----------+-----------+----------+------+------+------+------+--------+-----------+-----------+----------+----------+----------+----------+-------+-------+--------+--------+--------+-------+--------+-----------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(df) \n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f9230-43d9-4422-8970-c781fe81462d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16376f4d-1591-4903-8fdd-623391b8b771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75263adb-05af-4859-8c85-c90a86720c5e",
   "metadata": {},
   "source": [
    "## Define Sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a6865d-96e8-4aa4-8040-97a7e6a51663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysad.evaluation.metrics import AUROCMetric\n",
    "from pysad.models.loda import LODA\n",
    "from pysad.utils.data import Data\n",
    "from pysad.models.integrations import ReferenceWindowModel\n",
    "from pyod.models.hbos import HBOS\n",
    "from pysad.transform.postprocessing import RunningAveragePostprocessor\n",
    "from pysad.transform.preprocessing import InstanceUnitNormScaler\n",
    "from pysad.transform.probability_calibration import GaussianTailProbabilityCalibrator\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081a6c0a-fcec-4c38-8191-6b14fbdb5dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "wavingCounter unbiased estimation of frequencies\n",
    "wavingList store k' (k'>k) frequent items\n",
    "hashFunc to hash element to 1 or -1 increase or decrease wavingCounter\n",
    "element frequency\n",
    "If its frequency is larger than the smallest frequency in the list,we exchange them. \n",
    "\n",
    "Based on this idea, we use a group of WavingCounters and lists, and add additional fields in the list to achieve\n",
    "higher accuracy\n",
    "\"\"\"\n",
    "\n",
    "class WavingSketch:\n",
    "    def __init__(self, size):\n",
    "        self.arr = np.zeros((size,),dtype='f,f,f,f')\n",
    "        self.count = 0\n",
    "    def update(self,elem):\n",
    "        round(elem, 7)\n",
    "        # bucket[0]-->count bucket[1]-->elem bucket[2]-->frequency bucket[3]-->flag\n",
    "        bucket = self.arr[self.hashnum(elem)]\n",
    "        # estimated frequency calc\n",
    "        efreq = bucket[0]*self.hash1(elem)\n",
    "        if elem == bucket[1]:\n",
    "            bucket[2]+=1\n",
    "            if bucket[3]==False:\n",
    "                bucket[0]=bucket[0]+self.hash1(elem)\n",
    "        elif bucket[1] == 0:\n",
    "            bucket[1]=elem\n",
    "            bucket[2]=1\n",
    "            bucket[3]=True\n",
    "        else:\n",
    "            bucket[0]=bucket[0]+self.hash1(elem)\n",
    "            if efreq >= bucket[0]:\n",
    "                if bucket[3]==True:\n",
    "                    bucket[0]=bucket[0]+efreq*self.hash1(elem)\n",
    "                bucket[1]=elem\n",
    "                bucket[2]=efreq+1\n",
    "                bucket[3]=False\n",
    "            \n",
    "    def hash1(self,elem):\n",
    "        val = -1\n",
    "        if self.hashnum(elem)%2==0:\n",
    "            val = 1\n",
    "        return val\n",
    "    def hashnum(self,elem):\n",
    "        return hash(elem.__str__()) % len(self.arr)\n",
    "    \n",
    "    def ret(self):\n",
    "        return self.arr\n",
    "    \n",
    "def findkfreq(arr,k):\n",
    "    if k > len(arr):\n",
    "        return -1\n",
    "    freq=[]\n",
    "    for i in arr:\n",
    "        freq.append((i[0],i[1]))\n",
    "    freq.sort(reverse = True)\n",
    "    freq = freq[0:k]\n",
    "    return freq\n",
    "    #return [i[1] for i in freq]\n",
    "\n",
    "def findChange(arr1,arr2,k):\n",
    "    freq1=[]\n",
    "    freq2=[]\n",
    "    for i in arr1:\n",
    "        freq1.append((i[0],i[1]))\n",
    "    for j in arr2:\n",
    "        freq2.append((j[0],j[1]))\n",
    "    freqres=[]\n",
    "    for i in range(len(freq1)):\n",
    "        freqres.append(((freq2[i][0]-freq1[i][0],freq1[i][1])))\n",
    "    freqres.sort(reverse = True)\n",
    "    freqres = freqres[0:k]\n",
    "    return freqres\n",
    "    #return [i[1] for i in freqres]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71defe17-3e2f-403c-b7b9-492243a6988e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bccaa22-d0a5-41a2-b320-a301d313134c",
   "metadata": {},
   "source": [
    "## Defining DB credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63626ac0-5cca-4e74-9675-c1e65c10b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "token = 'Qd6R1JJWOOKfcKmBn0s50wHLqA-2LjLjEGJiUAGp1_RCes_JRe_bkELLYL5jqCXRQ1Haww3_mrHk_69yN88L0A=='\n",
    "org = 'ELTE'\n",
    "bucket = 'ELTE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a2b62-fafa-412b-ab7a-e123eece6e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea8244d-edf9-45d5-afa5-58356f8fe46e",
   "metadata": {},
   "source": [
    "### Creating the streams, scaling, WavingSketch and define Anomaly Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03cfc20-fc5c-46b1-9a9b-428cf2fc8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stream\n",
    "stream = np.array(sdf.select(\"LIT 301\", \"FIT 401\").collect())\n",
    "# Stream for wavingsketch\n",
    "attarr = np.array(sdf.select(\"FIT 401\").collect())\n",
    "\n",
    "# Scaled\n",
    "min_max_scale = MinMaxScaler()\n",
    "scaled = min_max_scale.fit_transform(stream)\n",
    "\n",
    "# Define Anomaly Detection sketch\n",
    "model = ReferenceWindowModel(model_cls=HBOS,  window_size=500, sliding_size=200,)\n",
    "preprocessor = InstanceUnitNormScaler()  # Normalizer\n",
    "postprocessor = RunningAveragePostprocessor(window_size=100)  # Running average postprocessor\n",
    "calibrator = GaussianTailProbabilityCalibrator(running_statistics=True, window_size=500)\n",
    "y_pred = []\n",
    "\n",
    "# Define the WavingSketch \n",
    "sketch= WavingSketch(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee269a51-2963-453a-88ad-0051373b1a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd5d77c-3279-4734-b59a-e483a08727c4",
   "metadata": {},
   "source": [
    "## Save In InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a09f250a-0e5b-436a-9341-05f3e44807e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14996/14996 [31:00<00:00,  8.06it/s] \n"
     ]
    }
   ],
   "source": [
    "with influxdb_client.InfluxDBClient(url=\"http://influxdb:8086\", token=token, org=org) as client:\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "    for i in tqdm(range(stream.shape[0])):\n",
    "        \n",
    "        # HBOS\n",
    "        X = preprocessor.fit_transform_partial(stream[i])\n",
    "        anomaly_score = model.fit_score_partial(X)\n",
    "        anomaly_score = postprocessor.fit_transform_partial(anomaly_score)\n",
    "        calibrated_score = calibrator.fit_transform_partial(anomaly_score)\n",
    "        p = influxdb_client.Point(\"anomaly_score_hbos\").field(\"Anomaly Score\", calibrated_score)\n",
    "        write_api.write(bucket, org, p) \n",
    "        \n",
    "        # WavingSketch\n",
    "        sketch.update(attarr[i][0])\n",
    "        samples=sketch.ret()\n",
    "        freq5 = findkfreq(samples,5)\n",
    "        for freqs in freq5:\n",
    "            p = influxdb_client.Point(\"WavingFreq FIT 401\").field(str(freqs[1]), freqs[0])\n",
    "            write_api.write(bucket, org, p)    \n",
    "            \n",
    "        # Save scaled data\n",
    "        p = influxdb_client.Point(\"scaled_sensor_lit_301\").field(\"Scaled Values\", scaled[i][0])\n",
    "        write_api.write(bucket, org, p) \n",
    "        p = influxdb_client.Point(\"scaled_sensor_fit_401\").field(\"Scaled Values\", scaled[i][1])\n",
    "        write_api.write(bucket, org, p)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1746ba-7388-41ea-b814-abab4f7ef903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
